{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a42bdcfc-de1c-4d59-8ee8-527ae06ec196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd5b820-3083-4606-b936-f06665b22a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class GroceryStoreDataset(Dataset):\n",
    "    def __init__(self, split: str, transform=None) -> None:\n",
    "        super().__init__()\n",
    "        self.root = Path(\"GroceryStoreDataset/dataset\")\n",
    "        self.split = split\n",
    "        self.paths, self.labels = self.read_file()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n",
    "        img = Image.open(self.root / self.paths[idx])\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def read_file(self) -> Tuple[List[str], List[int]]:\n",
    "        paths = []\n",
    "        labels = []\n",
    "        with open(self.root / f\"{self.split}.txt\") as f:\n",
    "            for line in f:\n",
    "                path, _, label = line.replace(\"\\n\", \"\").split(\", \")\n",
    "                paths.append(path)\n",
    "                labels.append(int(label))\n",
    "        return paths, labels\n",
    "\n",
    "    def get_num_classes(self) -> int:\n",
    "        return max(self.labels) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b48e2d11-bb4d-45ea-9ef8-9ecf54386f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in the dataset: 43\n"
     ]
    }
   ],
   "source": [
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Instantiate the datasets with the transform\n",
    "train_dataset = GroceryStoreDataset(split='train', transform=transform)\n",
    "val_dataset = GroceryStoreDataset(split='val', transform=transform)\n",
    "test_dataset = GroceryStoreDataset(split='test', transform=transform)\n",
    "\n",
    "# Calculate the number of classes from the train dataset\n",
    "num_classes = train_dataset.get_num_classes()\n",
    "print(f\"Number of classes in the dataset: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed832bdf-a255-437b-843b-4d67861196d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Bottleneck block\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, in_channels, mid_channels, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=32, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv3 = nn.Conv2d(mid_channels, mid_channels * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(mid_channels * self.expansion)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != mid_channels * self.expansion:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, mid_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(mid_channels * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Define the ResNeXt architecture\n",
    "class ResNeXt(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        super(ResNeXt, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 128, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 256, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 1024, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(1024 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, mid_channels, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, mid_channels, stride))\n",
    "        self.in_channels = mid_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, mid_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57dffed5-21cf-47e8-8370-4710c7280676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "def test_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a97ff56-5c16-4de8-9f45-4120f7f8aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7185298e-cb4c-4b23-bdf1-bdc1c5857012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 2.9263, Train Accuracy: 26.21%, Val Loss: 2.8523, Val Accuracy: 23.65%\n",
      "Epoch [2/20], Train Loss: 1.9148, Train Accuracy: 41.25%, Val Loss: 3.4350, Val Accuracy: 28.04%\n",
      "Epoch [3/20], Train Loss: 1.6592, Train Accuracy: 46.67%, Val Loss: 3.0935, Val Accuracy: 24.32%\n",
      "Epoch [4/20], Train Loss: 1.3402, Train Accuracy: 55.11%, Val Loss: 2.9053, Val Accuracy: 28.38%\n",
      "Epoch [5/20], Train Loss: 1.1897, Train Accuracy: 61.06%, Val Loss: 1.9029, Val Accuracy: 46.62%\n",
      "Epoch [6/20], Train Loss: 0.9309, Train Accuracy: 68.71%, Val Loss: 2.5602, Val Accuracy: 37.50%\n",
      "Epoch [7/20], Train Loss: 0.8629, Train Accuracy: 71.74%, Val Loss: 2.6008, Val Accuracy: 40.20%\n",
      "Epoch [8/20], Train Loss: 0.8444, Train Accuracy: 72.84%, Val Loss: 2.8186, Val Accuracy: 33.78%\n",
      "Epoch [9/20], Train Loss: 0.6117, Train Accuracy: 80.45%, Val Loss: 2.7902, Val Accuracy: 34.46%\n",
      "Epoch [10/20], Train Loss: 0.5606, Train Accuracy: 82.69%, Val Loss: 3.1688, Val Accuracy: 37.50%\n",
      "Epoch [11/20], Train Loss: 0.4781, Train Accuracy: 84.13%, Val Loss: 3.1655, Val Accuracy: 42.23%\n",
      "Epoch [12/20], Train Loss: 0.4956, Train Accuracy: 84.32%, Val Loss: 2.4152, Val Accuracy: 38.85%\n",
      "Epoch [13/20], Train Loss: 0.4654, Train Accuracy: 84.85%, Val Loss: 3.1088, Val Accuracy: 41.55%\n",
      "Epoch [14/20], Train Loss: 0.4103, Train Accuracy: 86.10%, Val Loss: 3.2458, Val Accuracy: 42.57%\n",
      "Epoch [15/20], Train Loss: 0.3995, Train Accuracy: 87.05%, Val Loss: 3.4383, Val Accuracy: 38.51%\n",
      "Epoch [16/20], Train Loss: 0.2062, Train Accuracy: 93.64%, Val Loss: 2.8554, Val Accuracy: 40.20%\n",
      "Epoch [17/20], Train Loss: 0.2697, Train Accuracy: 90.87%, Val Loss: 3.2084, Val Accuracy: 51.01%\n",
      "Epoch [18/20], Train Loss: 0.2672, Train Accuracy: 92.20%, Val Loss: 2.3591, Val Accuracy: 48.99%\n",
      "Epoch [19/20], Train Loss: 0.2317, Train Accuracy: 92.95%, Val Loss: 2.7795, Val Accuracy: 41.89%\n",
      "Epoch [20/20], Train Loss: 0.1290, Train Accuracy: 96.10%, Val Loss: 2.9391, Val Accuracy: 47.64%\n"
     ]
    }
   ],
   "source": [
    "# Part 1: Train custom ResNeXt-like model\n",
    "model = ResNeXt(Bottleneck, [3, 4, 6, 3], num_classes=num_classes).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d0e8ed9-b1c0-495e-b534-8fe966613812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.1650, Test Accuracy: 61.13%\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69f633-a811-4e07-8b58-2b1df77d3cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2557a28-c1fe-4430-908a-913cc9550a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17900a9f-e297-4580-9681-dcda136b1a10",
   "metadata": {},
   "source": [
    "'''part 2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91500bf3-6433-4bd4-8fd8-3be31cf29f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=43, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pretrained ResNet-18 model\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0570c972-67f6-4482-91c5-02ab847a8c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 1.0681, Train Accuracy: 71.67%, Val Loss: 2.3785, Val Accuracy: 46.62%\n",
      "Epoch [2/10], Train Loss: 0.2494, Train Accuracy: 92.99%, Val Loss: 0.9733, Val Accuracy: 72.97%\n",
      "Epoch [3/10], Train Loss: 0.1277, Train Accuracy: 96.40%, Val Loss: 1.4549, Val Accuracy: 60.14%\n",
      "Epoch [4/10], Train Loss: 0.1184, Train Accuracy: 97.05%, Val Loss: 2.0857, Val Accuracy: 52.03%\n",
      "Epoch [5/10], Train Loss: 0.1465, Train Accuracy: 95.42%, Val Loss: 2.1275, Val Accuracy: 56.08%\n",
      "Epoch [6/10], Train Loss: 0.1174, Train Accuracy: 96.70%, Val Loss: 2.5317, Val Accuracy: 52.36%\n",
      "Epoch [7/10], Train Loss: 0.1226, Train Accuracy: 96.48%, Val Loss: 1.6202, Val Accuracy: 62.50%\n",
      "Epoch [8/10], Train Loss: 0.0531, Train Accuracy: 98.52%, Val Loss: 1.0212, Val Accuracy: 69.59%\n",
      "Epoch [9/10], Train Loss: 0.0412, Train Accuracy: 98.86%, Val Loss: 1.1600, Val Accuracy: 69.93%\n",
      "Epoch [10/10], Train Loss: 0.0600, Train Accuracy: 98.56%, Val Loss: 1.5723, Val Accuracy: 63.51%\n",
      "Test Loss: 1.4794, Test Accuracy: 69.22%\n"
     ]
    }
   ],
   "source": [
    "# Use the same optimizer and learning rate as Part 1\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10)\n",
    "test_model(model, test_loader, criterion, device)\n",
    "\n",
    "# Part 2: Fine-tune pretrained ResNet-18 model with improved hyperparameters\n",
    "\n",
    "# Enhanced Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96ddebfc-a693-4953-ac67-c06c105a0116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-instantiate the datasets with enhanced transforms\n",
    "train_dataset = GroceryStoreDataset(split='train', transform=transform)\n",
    "val_dataset = GroceryStoreDataset(split='val', transform=transform)\n",
    "test_dataset = GroceryStoreDataset(split='test', transform=transform)\n",
    "\n",
    "# Re-instantiate the data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fddc9eb9-a949-4459-ac2e-60e22e8ec2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-instantiate the model and optimizer\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Use SGD with momentum for optimization\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2b3efd7-0611-469f-bd00-6d7a021bac97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 1.7148, Train Accuracy: 55.45%, Val Loss: 1.0203, Val Accuracy: 67.91%\n",
      "Epoch [2/20], Train Loss: 0.2254, Train Accuracy: 94.89%, Val Loss: 0.5576, Val Accuracy: 80.74%\n",
      "Epoch [3/20], Train Loss: 0.0759, Train Accuracy: 98.60%, Val Loss: 0.5776, Val Accuracy: 80.07%\n",
      "Epoch [4/20], Train Loss: 0.0383, Train Accuracy: 99.47%, Val Loss: 0.5021, Val Accuracy: 85.14%\n",
      "Epoch [5/20], Train Loss: 0.0336, Train Accuracy: 99.58%, Val Loss: 0.5976, Val Accuracy: 81.42%\n",
      "Epoch [6/20], Train Loss: 0.0625, Train Accuracy: 98.33%, Val Loss: 0.6100, Val Accuracy: 82.09%\n",
      "Epoch [7/20], Train Loss: 0.0182, Train Accuracy: 99.73%, Val Loss: 0.4704, Val Accuracy: 84.46%\n",
      "Epoch [8/20], Train Loss: 0.0111, Train Accuracy: 99.89%, Val Loss: 0.4598, Val Accuracy: 86.15%\n",
      "Epoch [9/20], Train Loss: 0.0106, Train Accuracy: 99.85%, Val Loss: 0.5347, Val Accuracy: 83.11%\n",
      "Epoch [10/20], Train Loss: 0.0117, Train Accuracy: 99.92%, Val Loss: 0.4371, Val Accuracy: 83.78%\n",
      "Epoch [11/20], Train Loss: 0.0072, Train Accuracy: 99.96%, Val Loss: 0.3978, Val Accuracy: 88.18%\n",
      "Epoch [12/20], Train Loss: 0.0085, Train Accuracy: 99.96%, Val Loss: 0.4387, Val Accuracy: 88.18%\n",
      "Epoch [13/20], Train Loss: 0.0043, Train Accuracy: 100.00%, Val Loss: 0.4217, Val Accuracy: 86.82%\n",
      "Epoch [14/20], Train Loss: 0.0030, Train Accuracy: 100.00%, Val Loss: 0.4048, Val Accuracy: 89.19%\n",
      "Epoch [15/20], Train Loss: 0.0030, Train Accuracy: 100.00%, Val Loss: 0.4120, Val Accuracy: 84.80%\n",
      "Epoch [16/20], Train Loss: 0.0032, Train Accuracy: 100.00%, Val Loss: 0.4368, Val Accuracy: 85.14%\n",
      "Epoch [17/20], Train Loss: 0.0040, Train Accuracy: 100.00%, Val Loss: 0.3845, Val Accuracy: 87.84%\n",
      "Epoch [18/20], Train Loss: 0.0030, Train Accuracy: 100.00%, Val Loss: 0.4016, Val Accuracy: 87.84%\n",
      "Epoch [19/20], Train Loss: 0.0025, Train Accuracy: 100.00%, Val Loss: 0.4114, Val Accuracy: 86.49%\n",
      "Epoch [20/20], Train Loss: 0.0021, Train Accuracy: 100.00%, Val Loss: 0.3823, Val Accuracy: 87.16%\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune with improved hyperparameters\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22769a41-e940-4e37-86d0-9668de9d4db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4361, Test Accuracy: 88.05%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the fine-tuned ResNet-18 model with improved hyperparameters\n",
    "test_model(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d9a76-8001-4238-b15a-4e0ccec92227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb6e503-a89f-4ee2-999e-a7c711281c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_pytorch_gpu",
   "language": "python",
   "name": "tf_pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
