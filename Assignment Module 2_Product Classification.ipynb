{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a42bdcfc-de1c-4d59-8ee8-527ae06ec196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd5b820-3083-4606-b936-f06665b22a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class GroceryStoreDataset(Dataset):\n",
    "    def __init__(self, split: str, transform=None) -> None:\n",
    "        super().__init__()\n",
    "        self.root = Path(\"GroceryStoreDataset/dataset\")\n",
    "        self.split = split\n",
    "        self.paths, self.labels = self.read_file()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n",
    "        img = Image.open(self.root / self.paths[idx])\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def read_file(self) -> Tuple[List[str], List[int]]:\n",
    "        paths = []\n",
    "        labels = []\n",
    "        with open(self.root / f\"{self.split}.txt\") as f:\n",
    "            for line in f:\n",
    "                path, _, label = line.replace(\"\\n\", \"\").split(\", \")\n",
    "                paths.append(path)\n",
    "                labels.append(int(label))\n",
    "        return paths, labels\n",
    "\n",
    "    def get_num_classes(self) -> int:\n",
    "        return max(self.labels) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b48e2d11-bb4d-45ea-9ef8-9ecf54386f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in the dataset: 43\n"
     ]
    }
   ],
   "source": [
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Instantiate the datasets with the transform\n",
    "train_dataset = GroceryStoreDataset(split='train', transform=transform)\n",
    "val_dataset = GroceryStoreDataset(split='val', transform=transform)\n",
    "test_dataset = GroceryStoreDataset(split='test', transform=transform)\n",
    "\n",
    "# Calculate the number of classes from the train dataset\n",
    "num_classes = train_dataset.get_num_classes()\n",
    "print(f\"Number of classes in the dataset: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed832bdf-a255-437b-843b-4d67861196d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Bottleneck block\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, in_channels, mid_channels, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=32, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv3 = nn.Conv2d(mid_channels, mid_channels * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(mid_channels * self.expansion)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != mid_channels * self.expansion:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, mid_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(mid_channels * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ead90d14-4a48-415b-86ac-40e99e624a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResNeXt architecture\n",
    "class ResNeXt(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        super(ResNeXt, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 128, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 256, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 1024, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(1024 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, mid_channels, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, mid_channels, stride))\n",
    "        self.in_channels = mid_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, mid_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57dffed5-21cf-47e8-8370-4710c7280676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = ResNeXt(Bottleneck, [3, 4, 6, 3], num_classes=num_classes)\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)\n",
    "\n",
    "# Datasets and DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a97ff56-5c16-4de8-9f45-4120f7f8aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training and validation loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "def test_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d0e8ed9-b1c0-495e-b534-8fe966613812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 2.8543, Train Accuracy: 27.50%, Val Loss: 5.4300, Val Accuracy: 16.55%\n",
      "Epoch [2/20], Train Loss: 1.9312, Train Accuracy: 42.01%, Val Loss: 2.5268, Val Accuracy: 31.76%\n",
      "Epoch [3/20], Train Loss: 1.6171, Train Accuracy: 48.83%, Val Loss: 2.8737, Val Accuracy: 31.42%\n",
      "Epoch [4/20], Train Loss: 1.3777, Train Accuracy: 56.29%, Val Loss: 2.5229, Val Accuracy: 44.26%\n",
      "Epoch [5/20], Train Loss: 1.1884, Train Accuracy: 60.34%, Val Loss: 2.0416, Val Accuracy: 39.53%\n",
      "Epoch [6/20], Train Loss: 1.0413, Train Accuracy: 66.10%, Val Loss: 2.2655, Val Accuracy: 40.88%\n",
      "Epoch [7/20], Train Loss: 0.8722, Train Accuracy: 71.86%, Val Loss: 3.0473, Val Accuracy: 35.14%\n",
      "Epoch [8/20], Train Loss: 0.7440, Train Accuracy: 75.91%, Val Loss: 2.3233, Val Accuracy: 41.22%\n",
      "Epoch [9/20], Train Loss: 0.6739, Train Accuracy: 77.27%, Val Loss: 1.9089, Val Accuracy: 47.97%\n",
      "Epoch [10/20], Train Loss: 0.5551, Train Accuracy: 81.48%, Val Loss: 1.9216, Val Accuracy: 43.24%\n",
      "Epoch [11/20], Train Loss: 0.4715, Train Accuracy: 84.43%, Val Loss: 3.5255, Val Accuracy: 44.59%\n",
      "Epoch [12/20], Train Loss: 0.4573, Train Accuracy: 85.34%, Val Loss: 3.3760, Val Accuracy: 35.81%\n",
      "Epoch [13/20], Train Loss: 0.4182, Train Accuracy: 86.40%, Val Loss: 2.4832, Val Accuracy: 43.92%\n",
      "Epoch [14/20], Train Loss: 0.2813, Train Accuracy: 90.98%, Val Loss: 3.1944, Val Accuracy: 41.55%\n",
      "Epoch [15/20], Train Loss: 0.3425, Train Accuracy: 88.45%, Val Loss: 2.9473, Val Accuracy: 49.66%\n",
      "Epoch [16/20], Train Loss: 0.3261, Train Accuracy: 88.94%, Val Loss: 2.8264, Val Accuracy: 41.22%\n",
      "Epoch [17/20], Train Loss: 0.2625, Train Accuracy: 91.74%, Val Loss: 2.6171, Val Accuracy: 45.27%\n",
      "Epoch [18/20], Train Loss: 0.2003, Train Accuracy: 93.71%, Val Loss: 2.2148, Val Accuracy: 49.66%\n",
      "Epoch [19/20], Train Loss: 0.2373, Train Accuracy: 92.31%, Val Loss: 2.3133, Val Accuracy: 49.66%\n",
      "Epoch [20/20], Train Loss: 0.1944, Train Accuracy: 94.36%, Val Loss: 2.4457, Val Accuracy: 48.65%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abbe502c-2d92-4be1-b6b7-89145803e5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.9772, Test Accuracy: 61.37%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_model(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69f633-a811-4e07-8b58-2b1df77d3cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_pytorch_gpu",
   "language": "python",
   "name": "tf_pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
